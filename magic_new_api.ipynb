{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update 20240215\n",
    "`akshare` stops working for retrieving fundamentals of us stocks. After research, I used https://www.dolthub.com/repositories/post-no-preference/earnings/query/master to get the Book Value, in order to compute PB. The code is modified accordingly. Alternatives APIs are in the Backup section  \n",
    "Changes include\n",
    "* Since APIs or query all limit calls of data, I need to first limit the number of stocks in analaysis, instead of retrieving info of all SP500 stocks\n",
    "\n",
    "## Methodology\n",
    "\n",
    "**Caveat**\n",
    "- In my first test (Stock_MA.ipynb), I use the first trading day of MONTH_ACT and first trading day of MONTH_PREV to define the the two ends of the 6m momentum. Here I use the Nth trading day instead. Therefore the result may vary\n",
    "- If stock splits, the price momentum is unreasonable, I will check it and likely skip that stockthat year\n",
    "- If using finviz\n",
    "  - The BV is updated with Q4 results for some stocks\n",
    "  - I can only use the whole SP500 instead of top 300\n",
    "  - The momentum filter is not by rank, but by value like 10% increase \n",
    "- The SP500 components change by about 20 each year. To accurately apply the magic formula, I should use the sp500 components of that year for backtest, but I don't have it. Here I'm using the latest SP500 list instead. There's an information leak, since those in today's SP500 but not 5 years ago must have been performing well to get into the list in the past 5 years. So I'm picking up those stocks that I know increases a lot in value, and putting in my portfolio to test the performance. \n",
    " - That said, I'm using top300 of sp500 which hopefully are more stable over time. And I have those strict criteria about momentum and PB. So the results should not be too far off\n",
    "\n",
    "\n",
    "**Methodology (for backtest)** \n",
    "Here I get daily price history data and use the price of the action day (The Nth trading day of the action month) to compute price momentum. Also I use a latest full list of SP500, but take only the first N_TOP_BY_MKT_CAP stocks.\n",
    "\n",
    "The follows are for the backtest. Prediction is similar except I only use one year's data and optimized parameters\n",
    "\n",
    "Method: \n",
    "- Select the N_TOP_BY_MKT_CAP top stocks from SP500\n",
    "- Starting from 2010, take actions on the Nth trading day of Feb (MONTH_ACT) of each year\n",
    "- First choose the top 20% (TOP_BY_MMT = 0.2) of stocks ranked by 6 month price momentum (price of the Nth trading day of MONTH_ACT minus price of the Nth trading day of previous MONTH_PREV)\n",
    "- Then choose the top N_STOCKS ranked by PB. PB = price of the Nth trading day of MONTH_ACT / book value of 2 quarters ago (previous Q3 if MONTH_ACT = Feb)\n",
    "- On the Nth trading day of MONTH_ACT of each year, sell all stocks from the previous year with tax rate of 10% (TAX_FACTOR = (1 - 0.1)), and buy new stocks with the money by repeating the previous two steps  \n",
    "\n",
    "**Parameters**\n",
    "- Tried different N_TOP_BY_MKT_CAP, and 300 is better than the fullist\n",
    "- Choose the top 40 gives good return among (30, 40, 50)\n",
    "- Each year, the gain (after 10% lt tax) is better than SPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import requests\n",
    "import certifi\n",
    "import json\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import akshare as ak  # https://github.com/akfamily/akshare\n",
    "\n",
    "from stocklib import pick_stocks, get_quarter\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which stock was split in the past year; check back after finding those anomalous momentum\n",
    "STOCK_SPLIT = ['IDONTKNOW']\n",
    "\n",
    "## When to buy and sell\n",
    "MONTH_ACT = 2  \n",
    "YEAR_ACT = 2024\n",
    "QUARTER_ACT = f'Q{MONTH_ACT // 3 + 1}'  # Dummy variable. If acting on Feb, the quarter is Q1\n",
    "\n",
    "# Starting year and month to compute 6m momentum\n",
    "if MONTH_ACT - 6 > 0:\n",
    "    MONTH_PREV = MONTH_ACT - 6\n",
    "    YEAR_PREV = YEAR_ACT \n",
    "else:\n",
    "   YEAR_PREV = YEAR_ACT - 1\n",
    "   MONTH_PREV = MONTH_ACT + 6  \n",
    "# The quarter for the BV. Since the ER date differs, this should be 2 quarters ahead of QUARTER_ACT\n",
    "# so that the BV is available for every stock. If acting in Q1, use previous Q3 \n",
    "QUARTER_BV = f'Q{MONTH_ACT // 3 + 3}'  \n",
    "# Trade on which trading day of the month. \n",
    "# The maximum of DOM varies by month; so be careful using a big value (> 20)\n",
    "# Previously I use the first day of the MONTH_ACT for convienience. Now using DOM_TRADING allows me to\n",
    "# compute on any day of the month. Note that the starting and end dates of 6m momentum is defined as \n",
    "# the Nth trading day of MONTH_PREV and that of MONTH_ACT, where N = DOM_TRADING. Therefore they do not\n",
    "# always fall on the same calendar day of month\n",
    "DOM_TRADING = 4 \n",
    "DATE_CUTOFF = f\"{YEAR_ACT}-{f'{MONTH_ACT}'.zfill(2)}-01\"  # To filter data without recent data\n",
    "\n",
    "## Filters to pick stocks and compute gains\n",
    "N_TOP_BY_MKT_CAP = 300  # Choose from the top N of sp500\n",
    "TOP_BY_MMT = 0.2  # The top fraction of stocks ranked by MMT\n",
    "MMT_VAR = 'stock_price_mmt_6m'\n",
    "TAX_FACTOR = (1 - 0.1)\n",
    "N_STOCKS = 40  # Number of stocks to buy\n",
    "TOTAL_CASH = 240000.0  # Total cash\n",
    "\n",
    "## Parameters for both backtest and prediction\n",
    "# Remove stocks with more than certain quarters with negatives BV. This is to reduce risks based on history.\n",
    "# When apply the magic formula, only stocks with PB > 0 of the MONTH_ACT are considered\n",
    "MAX_QUARTERS_NEG_PB = 40\n",
    "\n",
    "## Backtest only parameters\n",
    "YEAR_START = 2011  # backtest starting year\n",
    "CASH_FOR_EACH_STOCK = 1000  # backtest cash for each stock\n",
    "# Remove stocks with fewer than some quarters\n",
    "MIN_YEARS_TEST = 3  # Keep stocks with >= MIN_YEARS_TEST years of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = {\n",
    "    'fundamental': f'sp500_history_raw_{str(YEAR_ACT)}.csv',\n",
    "    'price': f'sp500_history_price_raw_{str(YEAR_ACT)}.csv',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download SP500 price data\n",
    "Downloading price takes about 0.5hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 3, ['MSFT' 'AAPL' 'NVDA']\n",
      "('AMZN', Timestamp('1997-05-16 00:00:00'), Timestamp('2024-02-14 00:00:00'), 6169)\n",
      "Saving...\n",
      "('META', Timestamp('2022-06-09 00:00:00'), Timestamp('2024-02-14 00:00:00'), 423)\n",
      "('GOOGL', Timestamp('2007-03-19 00:00:00'), Timestamp('2024-02-14 00:00:00'), 4257)\n",
      "('BRK.B', Timestamp('1996-05-09 00:00:00'), Timestamp('2024-02-14 00:00:00'), 6988)\n",
      "('AVGO', Timestamp('2016-02-01 00:00:00'), Timestamp('2024-02-14 00:00:00'), 2024)\n",
      "('LLY', Timestamp('1982-01-04 00:00:00'), Timestamp('2024-02-14 00:00:00'), 9428)\n",
      "('TSLA', Timestamp('2011-01-26 00:00:00'), Timestamp('2024-02-14 00:00:00'), 3256)\n",
      "('JPM', Timestamp('1983-12-30 00:00:00'), Timestamp('2024-02-14 00:00:00'), 9558)\n",
      "('UNH', Timestamp('1990-03-26 00:00:00'), Timestamp('2024-02-14 00:00:00'), 7983)\n",
      "('V', Timestamp('2008-03-19 00:00:00'), Timestamp('2024-02-14 00:00:00'), 4004)\n",
      "('XOM', Timestamp('2001-01-02 00:00:00'), Timestamp('2024-02-14 00:00:00'), 5261)\n",
      "('MA', Timestamp('2007-03-19 00:00:00'), Timestamp('2024-02-14 00:00:00'), 4257)\n",
      "('JNJ', Timestamp('1986-01-02 00:00:00'), Timestamp('2024-02-14 00:00:00'), 9045)\n",
      "('PG', Timestamp('1986-01-02 00:00:00'), Timestamp('2024-02-14 00:00:00'), 9046)\n",
      "('HD', Timestamp('1984-08-20 00:00:00'), Timestamp('2024-02-14 00:00:00'), 9397)\n",
      "('MRK', Timestamp('1986-01-02 00:00:00'), Timestamp('2024-02-14 00:00:00'), 9045)\n",
      "('COST', Timestamp('1986-07-09 00:00:00'), Timestamp('2024-02-14 00:00:00'), 8287)\n",
      "('ABBV', Timestamp('2013-07-25 00:00:00'), Timestamp('2024-02-14 00:00:00'), 2657)\n",
      "('ADBE', Timestamp('1986-08-14 00:00:00'), Timestamp('2024-02-14 00:00:00'), 8890)\n",
      "('CRM', Timestamp('2004-06-23 00:00:00'), Timestamp('2024-02-14 00:00:00'), 4258)\n",
      "('AMD', Timestamp('2015-01-05 00:00:00'), Timestamp('2024-02-14 00:00:00'), 2293)\n"
     ]
    }
   ],
   "source": [
    "## Get fundamental data (seasonal) or price data (daily) \n",
    "# Download all SP500 instead of N_TOP_BY_MKT_CAP, since later filters will remove some\n",
    "\n",
    "is_download = True\n",
    "is_from_scratch = True  # If starting from scratch and no stock data has been downloaded already\n",
    "to_download = 'price'  # 'fundamental' or 'price', download fundamental or price data\n",
    "\n",
    "if is_download:    \n",
    "    min_row = {\n",
    "        'fundamental': 3,\n",
    "        'price': 50,\n",
    "    }\n",
    "    anom = {'Failed_PB': [], 'Short': [], 'Failed_P': []}\n",
    "\n",
    "    # Get stock list (ordered by capital)\n",
    "    df_sp500_list = pd.read_excel('sp500_fulllist_ranked.xlsx', engine='openpyxl', sheet_name=str(YEAR_ACT))\n",
    "    stocks = df_sp500_list.loc[df_sp500_list['stock'] != 'GOOG', 'stock'].values.tolist()\n",
    "    stocks.append('OHI')  # I like OHI\n",
    "\n",
    "    if not is_from_scratch: \n",
    "        print('Read downloaded stocks from local file')\n",
    "        df_stock_all = pd.read_csv(file_name[to_download])\n",
    "\n",
    "    # If df_stock_all does not ecist, declare it\n",
    "    try:\n",
    "        df_stock_all       \n",
    "    except NameError: \n",
    "        df_stock_all = pd.DataFrame()\n",
    "    stock_downloaded = [] if df_stock_all.empty else df_stock_all.stock.unique()\n",
    "    print(f'Downloaded {len(stock_downloaded)}, {stock_downloaded}')\n",
    "\n",
    "    count = 0\n",
    "    for stock_symbol in stocks:\n",
    "        if stock_symbol in stock_downloaded:\n",
    "            continue\n",
    "        try:\n",
    "            if to_download == 'price':  # Download price\n",
    "                df_stock = ak.stock_us_daily(symbol=stock_symbol)\n",
    "                df_stock = df_stock.reset_index()  # Set the date index to a column\n",
    "            else:\n",
    "                print('Wrong variable name')\n",
    "        except IndexError:\n",
    "            print(f'Failed for {stock_symbol}')\n",
    "            anom['Failed_P'].append(stock_symbol)\n",
    "            continue        \n",
    "        df_stock['stock'] = stock_symbol\n",
    "        df_stock_all = pd.concat([df_stock_all, df_stock], ignore_index=True)\n",
    "        print(f\"{(stock_symbol, df_stock.date.min(), df_stock.date.max(), len(df_stock))}\")\n",
    "        if len(df_stock) < min_row[to_download]:\n",
    "            anom['Short'].append(stock_symbol)\n",
    "\n",
    "        count += 1\n",
    "        if count % 50 == 1:\n",
    "            print('Saving...')\n",
    "            df_stock_all.to_csv(file_name[to_download], index=False)    \n",
    "        time.sleep(5)        \n",
    "\n",
    "        if count > 20:\n",
    "            break\n",
    "\n",
    "    df_stock_all.to_csv(file_name[to_download], index=False)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get price momentum and filter by mkt share\n",
    "## Get price momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yuwei\\AppData\\Local\\Temp\\ipykernel_10000\\3454374815.py:6: FutureWarning: The provided callable <built-in function max> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
      "  df_p_history['max_date'] = df_p_history.groupby('stock')['date'].transform(max)\n"
     ]
    }
   ],
   "source": [
    "df_p_history = pd.read_csv(file_name[\"price\"])\n",
    "df_p_history[\"date\"] = pd.to_datetime(df_p_history[\"date\"])\n",
    "\n",
    "## Remove stocks that didn't last until the recent\n",
    "dt_cutoff = pd.to_datetime(DATE_CUTOFF)\n",
    "df_p_history[\"max_date\"] = df_p_history.groupby(\"stock\")[\"date\"].transform(max)\n",
    "df_p_history = (df_p_history[df_p_history[\"max_date\"] >= dt_cutoff]).drop(\n",
    "    \"max_date\", axis=1\n",
    ")\n",
    "\n",
    "## Get the starting and end dates to compute the momentum\n",
    "# The starting date is the DOM_TRAIDING day of MONTH_ACT, and the end date is\n",
    "# the DOM_TRAIDING day of MONTH_PREV. The two may not be the same calendar DOM\n",
    "df_p_history = df_p_history.sort_values([\"stock\", \"date\"])\n",
    "df_p_history[\"year\"] = df_p_history.date.dt.year\n",
    "df_p_history[\"month\"] = df_p_history.date.dt.month\n",
    "df_p_history[\"dom_trading\"] = df_p_history.groupby([\"stock\", \"year\", \"month\"])[\n",
    "    \"date\"\n",
    "].rank()\n",
    "df_p_history_prev = df_p_history[\n",
    "    (df_p_history.month == MONTH_PREV) & (df_p_history.dom_trading == DOM_TRADING)\n",
    "].copy()\n",
    "df_p_history_curr = df_p_history[\n",
    "    (df_p_history.month == MONTH_ACT) & (df_p_history.dom_trading == DOM_TRADING)\n",
    "].copy()\n",
    "\n",
    "## Use year_prev to join two datasets.\n",
    "# For 6month range, if MONTH_ACT is Jul-Dec, the year (year_prev) of MONTH_PREV is\n",
    "# the same year; otherwise its the previous year\n",
    "df_p_history_curr[\"year_prev\"] = (\n",
    "    df_p_history_curr.year if MONTH_ACT - 6 > 0 else df_p_history_curr.year - 1\n",
    ")\n",
    "\n",
    "df_p_history_prev[\"year_prev\"] = df_p_history_prev.year\n",
    "cols = [\"date\", \"close\", \"stock\", \"year_prev\"]\n",
    "df_p_history_mmt = pd.merge(\n",
    "    df_p_history_prev[cols],\n",
    "    df_p_history_curr[cols + [\"year\"]],\n",
    "    on=[\"stock\", \"year_prev\"],\n",
    "    suffixes=[\"_prev\", \"\"],\n",
    ")\n",
    "\n",
    "## Get the momentum\n",
    "df_p_history_mmt[\"stock_price_mmt_6m\"] = (\n",
    "    df_p_history_mmt[\"close\"] / df_p_history_mmt[\"close_prev\"] - 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get top N by THIS YEAR'S market cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 of stocks after filtering by MKT CAP\n"
     ]
    }
   ],
   "source": [
    "# Choose only the top N companies of SP500 to start with\n",
    "df_rank = pd.read_excel('sp500_fulllist_ranked.xlsx', engine='openpyxl', sheet_name=str(YEAR_ACT))\n",
    "top_stocks = df_rank[df_rank['rank'] <= N_TOP_BY_MKT_CAP].stock.values\n",
    "df_p_history_mmt = df_p_history_mmt[df_p_history_mmt.stock.isin(top_stocks)]\n",
    "\n",
    "print(f'{df_p_history_mmt.stock.nunique()} of stocks after filtering by MKT CAP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply the magic formula for a certain year\n",
    "## Look for anoumalous mmt to detect split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_row = df_p_history_mmt[df_p_history_mmt.year == YEAR_ACT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check mmt anomalies manually\n",
    "# df_row.sort_values('stock_price_mmt_6m')\n",
    "\n",
    "# Check stocks with super low mmt on tradingview to see if they had a split\n",
    "# STOCK_SPLIT = ['TSLA', 'CPRT', ]  # And their momentum is low; just remove them\n",
    "# stocks_split = STOCK_SPLIT\n",
    "# df_row = df_row[~df_row.stock.isin(stocks_split)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter by momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 of stocks after filtering by momentum\n"
     ]
    }
   ],
   "source": [
    "mmt_var = MMT_VAR\n",
    "top_by_mmt = TOP_BY_MMT\n",
    "df_top_by_mmt = (\n",
    "    df_row.sort_values(mmt_var, ascending=False).iloc[: round(len(df_row) * top_by_mmt), :]\n",
    ")\n",
    "print(f'{df_top_by_mmt.stock.nunique()} of stocks after filtering by momentum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download price book ratio of filtered stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A test case\n",
    "# df_sp500_list_2023 = pd.read_excel('magic_stocks.xlsx', engine='openpyxl', sheet_name='2023')\n",
    "# stock_list = df_sp500_list_2023.stock.values\n",
    "# print(stock_list)\n",
    "\n",
    "stock_list = df_top_by_mmt.stock.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELECT act_symbol as stock, `date`, book_value_per_share\n",
      "FROM `balance_sheet_equity`\n",
      "WHERE act_symbol IN ('LLY', 'NVDA', 'META', 'AMD', 'AVGO')\n",
      "    AND period = 'Quarter'\n",
      "    AND `date` > '2023-01-01' \n",
      "ORDER BY `date` DESC\n",
      "LIMIT 1000;\n",
      " \n",
      " dolthub_bv_2024.csv\n"
     ]
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "SELECT act_symbol as stock, `date`, book_value_per_share\n",
    "FROM `balance_sheet_equity`\n",
    "WHERE act_symbol IN ('{\"', '\".join(stock_list)}')\n",
    "    AND period = 'Quarter'\n",
    "    AND `date` > '2023-01-01' \n",
    "ORDER BY `date` DESC\n",
    "LIMIT 1000;\n",
    "\"\"\"\n",
    "# Download data from https://www.dolthub.com/repositories/post-no-preference/earnings/query/master\n",
    "# And save to file\n",
    "bv_file_name = f\"dolthub_bv_{str(YEAR_ACT)}.csv\"\n",
    "\n",
    "print(query, '\\n', bv_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 stocks with the right quarter \n",
      "Stocks without Q3 data are set()\n"
     ]
    }
   ],
   "source": [
    "# Read downloaded .csv from the website above\n",
    "df_bv = pd.read_csv(bv_file_name)\n",
    "df_stock_sub = get_quarter(df_bv)\n",
    "df_stock_sub = df_stock_sub.drop(['DATE', 'dayofyear', ], axis=1).sort_values(['date', 'stock'])\n",
    "\n",
    "## Check if there is any anomalous pbs\n",
    "## Replace inf pb to 0\n",
    "# df_stock_sub = df_stock_sub.replace(np.inf, 0)\n",
    "# Remove stocks with over MAX_QUARTERS_NEG_PB quarters with neg equity (pb)\n",
    "# df_stock_sub_neg = df_stock_sub[df_stock_sub.price_to_book_ratio < 0].groupby('stock').size()\n",
    "# stocks_sub_neg = df_stock_sub_neg[df_stock_sub_neg >= MAX_QUARTERS_NEG_PB].index.values\n",
    "# df_stock_sub = df_stock_sub[~df_stock_sub.stock.isin(stocks_sub_neg)]\n",
    "# print(f'{df_stock_sub.stock.nunique()} stocks remained after filtering by neg BV')\n",
    "\n",
    "## Get data for the quarter needed\n",
    "df_pb_history = df_stock_sub\n",
    "df_pb_quarter = (df_pb_history[df_pb_history.index.str.endswith(QUARTER_BV)][['date', 'book_value_per_share', 'stock', 'year']]\n",
    "                     .reset_index(drop=True)\n",
    "                     .rename({'year': 'year_prev'}, axis=1)\n",
    "                )\n",
    "print(f'{df_pb_quarter.stock.nunique()} stocks with the right quarter', \n",
    "      f'\\nStocks without {QUARTER_BV} data are {set(df_pb_history.stock.unique()) - set(df_pb_quarter.stock.unique())}'\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually check and fill stocks with BV failure\n",
    "I only filled data for the last quarter for prediction only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>book_value_per_share</th>\n",
       "      <th>stock</th>\n",
       "      <th>year_prev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>53.50</td>\n",
       "      <td>AVGO</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>11.13</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>34.03</td>\n",
       "      <td>AMD</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>11.91</td>\n",
       "      <td>LLY</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>55.53</td>\n",
       "      <td>META</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  book_value_per_share stock  year_prev\n",
       "0  2023-07-31                 53.50  AVGO       2023\n",
       "1  2023-07-31                 11.13  NVDA       2023\n",
       "2  2023-09-30                 34.03   AMD       2023\n",
       "3  2023-09-30                 11.91   LLY       2023\n",
       "4  2023-09-30                 55.53  META       2023"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_pb_quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stocks_failed_pb = ['GM', 'HSY', 'CSGP', 'STT' ]  #  anom['Failed_P']\n",
    "# stocks_failed_pb_bv = [48.95, 15.26, 16.49, 69.7]   # get from https://www.macrotrends.net/\n",
    "\n",
    "# df_stocks_failed_pb = pd.DataFrame([\n",
    "#     [df_pb_quarter.date.max()] * len(stocks_failed_pb),\n",
    "#     [np.nan] * len(stocks_failed_pb),\n",
    "#     stocks_failed_pb_bv,\n",
    "#     stocks_failed_pb,\n",
    "#     [df_pb_quarter.year_prev.max()] * len(stocks_failed_pb)\n",
    "# ]).T\n",
    "# df_stocks_failed_pb.columns = df_pb_quarter.columns\n",
    "\n",
    "# df_pb_quarter = df_pb_quarter.append(df_stocks_failed_pb)\n",
    "# print(f'{df_pb_quarter.stock.nunique()} stocks after manully filling in those failing in PB download')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p_pb = pd.merge(df_p_history_mmt[['stock', 'year_prev', 'date', 'close', \n",
    "                                     'year', 'stock_price_mmt_6m']], \n",
    "                   df_pb_quarter, \n",
    "                   on=['stock', 'year_prev'], \n",
    "                   suffixes=['', '_pb'])\\\n",
    "            .rename({'close': 'stock_price'}, axis=1)\\\n",
    "            .drop(['year_prev'], axis=1)\n",
    "\n",
    "df_p_pb['price_to_book_ratio'] = df_p_pb['stock_price'] / df_p_pb['book_value_per_share']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yuwei\\Tools\\stocks\\stocklib.py:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  stocks_by_mmt_pb_simple[mmt_var + \"_pct\"] = (\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock</th>\n",
       "      <th>shares</th>\n",
       "      <th>stock_price</th>\n",
       "      <th>price_to_book_ratio</th>\n",
       "      <th>book_value_per_share</th>\n",
       "      <th>stock_price_mmt_6m_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMD</td>\n",
       "      <td>36.0</td>\n",
       "      <td>167.88</td>\n",
       "      <td>4.933294</td>\n",
       "      <td>34.03</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AVGO</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1222.65</td>\n",
       "      <td>22.853271</td>\n",
       "      <td>53.50</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LLY</td>\n",
       "      <td>9.0</td>\n",
       "      <td>705.03</td>\n",
       "      <td>59.196474</td>\n",
       "      <td>11.91</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>META</td>\n",
       "      <td>13.0</td>\n",
       "      <td>454.72</td>\n",
       "      <td>8.188727</td>\n",
       "      <td>55.53</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>9.0</td>\n",
       "      <td>682.23</td>\n",
       "      <td>61.296496</td>\n",
       "      <td>11.13</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stock  shares  stock_price  price_to_book_ratio  book_value_per_share  \\\n",
       "0   AMD    36.0       167.88             4.933294                 34.03   \n",
       "1  AVGO     5.0      1222.65            22.853271                 53.50   \n",
       "2   LLY     9.0       705.03            59.196474                 11.91   \n",
       "3  META    13.0       454.72             8.188727                 55.53   \n",
       "4  NVDA     9.0       682.23            61.296496                 11.13   \n",
       "\n",
       "   stock_price_mmt_6m_pct  \n",
       "0                    45.0  \n",
       "1                    39.0  \n",
       "2                    57.0  \n",
       "3                    46.0  \n",
       "4                    53.0  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks_invested = pick_stocks(df_p_pb, \n",
    "                              cash_to_invest=TOTAL_CASH,\n",
    "                              n_stocks=N_STOCKS, \n",
    "                              mmt_var=MMT_VAR, \n",
    "                             )\n",
    "stocks_invested['shares'] = stocks_invested['shares'].round()\n",
    "stocks_invested.sort_values('stock').reset_index(drop=True)\n",
    "\n",
    "# https://finviz.com/screener.ashx?v=150&f=idx_sp500,ta_perf_26w20o&ft=4&o=pb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use API to download fundamental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('api.my', 'r') as hf:\n",
    "    fmg_api_key = hf.read()  # financialmodelingprep, no quaterly data\n",
    "def get_jsonparsed_data(url):\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    requestResponse = requests.get(url, headers=headers)\n",
    "    return requestResponse.json()\n",
    "# def get_jsonparsed_data(url):\n",
    "#     response = urlopen(url, cafile=certifi.where())\n",
    "#     data = response.read().decode(\"utf-8\")\n",
    "#     return json.loads(data)\n",
    "\n",
    "\n",
    "# APIs\n",
    "av_api_key = ''  # alphavantage, Working. Seems not straightforward to cancel subscription\n",
    "pg_api_key = ''  # Polygon, can't retrieve fundamental data\n",
    "tg_api_key = ''  # tiingo, fundamental data requires add-on and monthly subs\n",
    "# Other apis: https://www.fmpcloud.io/plans/, https://data.nasdaq.com/databases/SF1#usage, https://github.com/theOGognf/finagg (promising)\n",
    "\n",
    "\n",
    "\n",
    "bv_raw = {}\n",
    "bv_list = []\n",
    "stock_list = df_sp500_list_2023.stock.values  # df_top_by_mmt['stock'].unique()\n",
    "for symbol in stock_list[:1]:\n",
    "    # url = (f\"https://financialmodelingprep.com/api/v3/balance-sheet-statement/{symbol}?period=annual&apikey={api_key}\")\n",
    "    # url = f\"https://www.alphavantage.co/query?function=BALANCE_SHEET&symbol={symbol}&apikey={av_api_key}\"\n",
    "    url = f\"https://api.tiingo.com/tiingo/fundamentals/{symbol}/statements?token={tg_api_key}\"\n",
    "    bv_raw[symbol] = get_jsonparsed_data(url)\n",
    "    for data in bv_raw[symbol]:\n",
    "        balance_sheet = {i['dataCode']: i['value'] for i in data['statementData']['balanceSheet'] if i['dataCode'] in ['equity', 'sharesBasic']}\n",
    "        bv_list.append((symbol, data['date'], balance_sheet['equity'], balance_sheet['sharesBasic']))\n",
    "df_bv = pd.DataFrame(bv_list, columns=('stock', 'date', 'book_value', 'shares_outstanding'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Market Cap data \n",
    "us_stock_em = ak.stock_us_spot_em()\n",
    "us_stock_em[['symbol_prefix', 'symbol']] = us_stock_em['代码'].str.split('.').tolist()\n",
    "us_stock_em = us_stock_em.rename({'总市值': 'mktCap'}, axis=1)\n",
    "df_merged = pd.merge(df_bv, us_stock_em[['mktCap', 'symbol']], on='symbol')\n",
    "df_merged['pb'] = df_merged['mktCap'] / df_merged['book_value']\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286 of stocks after filtering by length and starting date\n"
     ]
    }
   ],
   "source": [
    "# Remove data with too short length and too late starting date\n",
    "df_p_pb_size = df_p_pb.groupby('stock').size() \n",
    "df_p_pb_cut = df_p_pb[(df_p_pb.year >= YEAR_START) & \n",
    "                      (df_p_pb.stock.isin(df_p_pb_size[df_p_pb_size >= MIN_YEARS_TEST].index.values))]\n",
    "print(f'{df_p_pb_cut.stock.nunique()} of stocks after filtering by length and starting date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_by_mmt = TOP_BY_MMT\n",
    "rsl_lt = pd.DataFrame()\n",
    "# Number of stocks to choose by PB\n",
    "for n_stocks in [30, 40, 50]:  \n",
    "    # Invest method:\n",
    "    # - At the beginning, get the top_by_mmt fraction of stocks ranked by MMT, \n",
    "    #   And choose the top n_stocks stocks ranked by PB\n",
    "    # - After each holding period (PERIOD_HOLD), sell all stocks, and repurchase \n",
    "    #   with the initial methods\n",
    "    cash_to_invest = CASH_FOR_EACH_STOCK * n_stocks\n",
    "    cash_to_invest_prev = cash_to_invest\n",
    "\n",
    "    # Run over time\n",
    "    is_start = True\n",
    "    period_cnt = 1\n",
    "    for k, df_row in df_p_pb_cut.groupby('year'):    \n",
    "\n",
    "        # Initialize\n",
    "        if is_start:\n",
    "            stocks_invested = pick_stocks(df_row, \n",
    "                              cash_to_invest=cash_to_invest, \n",
    "                              n_stocks=n_stocks, \n",
    "                              mmt_var=MMT_VAR, \n",
    "                              top_by_mmt=top_by_mmt\n",
    "                             )\n",
    "            is_start = False\n",
    "            continue\n",
    "        \n",
    "        df_start = pd.merge(df_row[['stock', 'stock_price']], stocks_invested, on='stock', suffixes=('', '_bought'))\n",
    "        values = (df_start['shares'] * df_start['stock_price']).sum()\n",
    "        \n",
    "        # Take action\n",
    "        cash_to_invest_prev = cash_to_invest\n",
    "        # Tax\n",
    "        if values > cash_to_invest_prev:\n",
    "            cash_to_invest = (values - cash_to_invest_prev) * TAX_FACTOR + cash_to_invest_prev\n",
    "        else:\n",
    "            cash_to_invest = values\n",
    "        stocks_invested = pick_stocks(df_row, \n",
    "                                      cash_to_invest=cash_to_invest, \n",
    "                                      n_stocks=n_stocks, \n",
    "                                      mmt_var=MMT_VAR, \n",
    "                                      top_by_mmt=top_by_mmt\n",
    "                                     )\n",
    "        rsl_lt = rsl_lt.append(\n",
    "            pd.DataFrame([k, round(values), \n",
    "                          round(values / (CASH_FOR_EACH_STOCK * n_stocks), 3), len(df_start),\n",
    "                          n_stocks, MMT_VAR, 'lt_1', ], \n",
    "                         index=['year', 'value', 'return_overall', 'n_stocks_actual',\n",
    "                                'n_stocks', 'MMT_VAR', 'method', ]).T) \n",
    "\n",
    "        period_cnt += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get SPY history\n",
    "spy0 = ak.stock_us_daily(symbol=\"SPY\", adjust=\"\").reset_index()\n",
    "spy = spy0.copy()\n",
    "spy['year'] = spy.date.dt.year\n",
    "spy['month'] = spy.date.dt.month\n",
    "spy['dom_trading'] = spy.groupby(['year', 'month'])['date'].rank()\n",
    "\n",
    "# Get the first day of MONTH_PREV and of MONTH_ACT, compute the momentum\n",
    "spy_curr = spy[(spy.month == MONTH_ACT) & (spy.dom_trading == DOM_TRADING)]\n",
    "\n",
    "spy_curr_cut = spy_curr[spy_curr.year >= YEAR_START]\n",
    "spy_curr_cut['return_overall'] = (spy_curr_cut['close'] / \n",
    "                                  spy_curr_cut[spy_curr_cut.year == YEAR_START]['close'].\\\n",
    "                                  values[0]\n",
    "                                 ).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>n_stocks_actual</th>\n",
       "      <th>N_STOCKS</th>\n",
       "      <th>return_overall</th>\n",
       "      <th>return_overall_spy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2020</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>2.255</td>\n",
       "      <td>2.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2020</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>2.805</td>\n",
       "      <td>2.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2020</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>3.042</td>\n",
       "      <td>2.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2021</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>3.059</td>\n",
       "      <td>2.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>2021</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>3.664</td>\n",
       "      <td>2.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>2021</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>4.032</td>\n",
       "      <td>2.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2022</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>5.077</td>\n",
       "      <td>3.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>2022</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>5.6</td>\n",
       "      <td>3.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>2022</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>5.846</td>\n",
       "      <td>3.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>2023</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>5.259</td>\n",
       "      <td>3.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>2023</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>5.852</td>\n",
       "      <td>3.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>2023</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>6.184</td>\n",
       "      <td>3.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year n_stocks_actual N_STOCKS return_overall  return_overall_spy\n",
       "24  2020              30       30          2.255                2.48\n",
       "25  2020              40       40          2.805                2.48\n",
       "26  2020              50       50          3.042                2.48\n",
       "27  2021              30       30          3.059                2.88\n",
       "28  2021              40       40          3.664                2.88\n",
       "29  2021              50       50          4.032                2.88\n",
       "30  2022              30       30          5.077                3.46\n",
       "31  2022              40       40            5.6                3.46\n",
       "32  2022              50       50          5.846                3.46\n",
       "33  2023              30       30          5.259                3.14\n",
       "34  2023              40       40          5.852                3.14\n",
       "35  2023              50       50          6.184                3.14"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compare = pd.merge(rsl_lt, spy_curr_cut[['year', 'return_overall']], \n",
    "                      on='year', \n",
    "                      suffixes=['', '_spy']).sort_values(['n_stocks', 'year'])\n",
    "df_compare[df_compare.year.isin(\n",
    "    [2020, 2021, 2022, 2023]\n",
    "#     range(2011, 2024)\n",
    ")][\n",
    "    ['year', 'n_stocks_actual', 'n_stocks', 'return_overall', 'return_overall_spy']\n",
    "].sort_values(['year', 'n_stocks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N_STOCKS\n",
       "30    1.0\n",
       "40    2.5\n",
       "50    2.5\n",
       "Name: rank_n_stock, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The higher the rank means the more years with best return\n",
    "df_compare['return_overall'] = df_compare['return_overall'].astype(float)\n",
    "df_compare['rank_n_stock'] = \\\n",
    "    df_compare.groupby('year')['return_overall'].rank()\n",
    "df_compare.groupby('n_stocks')['rank_n_stock'].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "234.517px"
   },
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
